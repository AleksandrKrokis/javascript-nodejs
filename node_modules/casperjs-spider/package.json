{
  "name": "casperjs-spider",
  "version": "0.6.1",
  "description": "Use CasperJS to crawl sites and report issues.",
  "main": "config.js",
  "dependencies": {},
  "devDependencies": {},
  "repository": {
    "type": "git",
    "url": "git://github.com/seethroughtrees/casperjs-spider.git"
  },
  "author": {
    "name": "seethroughtrees"
  },
  "license": "ISC",
  "bugs": {
    "url": "https://github.com/seethroughtrees/casperjs-spider/issues"
  },
  "homepage": "https://github.com/seethroughtrees/casperjs-spider",
  "readme": "### The fork adds support for broken img[src]/iframe[src], also logs errors with referencing pages in file.\n\n*Fully refactored and tested with Casper 1.0.x and 1.1.x beta.\nPlease note the compatibility change for casperjs/phantomjs in their docs*\n\n# Spider for CasperJS\n\nThis script uses [casperJS](http://casperjs.org/) to crawl your site and log all urls, response codes, errors and warnings to a json file for parsing.\n\n--------\n\n### What casperjs-spider does\n\n- Spiders whatever site you want it to\n- Returns list of:\n  - all links with response codes\n  - all javascript errors from console\n  - all ssl insecure warnings\n  - all warning messages\n- Does not repeat URLs\n- Allows you to skip specified terms\n- Allows you to require specified terms\n- Exports a data.json file with your results\n\n### Getting Started\n\nMake sure you have [casperJS](http://casperjs.org/) and [phantomJS](http://phantomjs.org/) installed.\n\n\nConfigure the script by setting your config options in config.js or passing arguments in the command line.\n\nIn your terminal, navigate to the folder containing the spider.js file.\n\n- Using config.js settings:\n\n``` casperjs spider.js ```\n\n- Configuring with arguments:\n\n``` casperjs --start-url=http://example.com --required-values=example.com spider.js ```\n\n*Casper arguments go in the middle, and they will override config options in the script.*\n\n### Config Options\n\nThere are several configuration options in casperjs-spider.  You can set them individually in the command line, or by editing the config portion of [spider.js](https://github.com/pensive612/casperjs-spider/blob/master/spider.js).\n\n*It might help to refer to the default config options in [config.js](https://github.com/pensive612/casperjs-spider/blob/master/config.js) for examples*\n\n**start-url** *\\*required*\n\n- Also defined as config.startUrl in config.js.  This is the starting URL for your spider to crawl.\n- ```--start-url=http://example.com```\n- ```config.startUrl = 'http://example.com';```\n\n**required-values** *\\*required*\n\n- Also defined as config.requiredValues in config.js.  This is a comma-separated list of all required strings.\n- ```--required-values=example.com```\n- ```config.requiredValues = 'example.com';```\n- *Make sure you put your top-level domain in here to keep from spidering the internet!*\n- Leave off the protocol so it will allow for subdomains if you have them.\n\n**skipped-values**\n\n- Also defined as config.skippedValues in config.js.  This is a comma-separated list of all skipped strings.\n- *It might be helpful to skip URLs like mailto, install, forums, blogs etc...*\n- ```--skipped-values=mailto,install,\\#,blog/,comment```\n- ```config.skippedValues = 'mailto,install,#,blog/,comment';```\n\n**limit**\n\n- Also defined as config.limit in config.js.  This is a numeric limit to the links logged.\n- Enter 0, or omit for no limit.\n- ```--limit=25```\n- ```config.limit = 25```\n\n**file-location** *default=./logs/*\n\n- Also defined as config.fileLocation in config.js.  This is a path to where you want the data.json file to be saved.\n- ```--file-location=./logs/```\n- ```config.fileLocation = './logs/';```\n\n**date-file-name** *default=false*\n\n- Also defined as config.dateFileName in config.js.  This is a boolean to replace the filename data.json with the current date.  ie.  2013-12-22.json.  In case you want to keep versions.\n- ```--date-file-name=false```\n- ```config.dateFileName = false;```\n\n**verbose** *default=false*\n\n- Also defined as config.verbose in config.js.  This is a boolean to put casper into verbose mode.\n- ```--verbose=false```\n- ```config.verbose = false;```\n\n**log-level** *default=error*\n\n- Also defined as config.logLevel in config.js.  SpiderJS allows you to set a logging level. can be [error, warning, info, debug]\n- ```--log-level=error```\n- ```config.logLevel = 'error';```\n\n**load-images** *default=false*\n\n- Also defined as config.loadImages in config.js.  SpiderJS allows you to disable images from loading in the crawler.  This speeds up the crawl, and is generally not necessary for output.\n- ```--load-images=false```\n- ```config.loadImages = 'false';```\n\n**load-plugins** *default=false*\n\n- Also defined as config.loadPlugins in config.js.  SpiderJS allows you to disable plugins from loading in the crawler.  This speeds up the crawl, and is generally not necessary for output.\n- ```--load-plugins=false```\n- ```config.loadPlugins = 'false';```\n\n\n\n### Contributing\n\nFeel free to edit for yourself, or send a pull-request with any improvements.\n\n**Any pull-requests should be pulled from master and sent to separate branch prefixed with incoming-.**\n\nThis script wouldn't be possible without [PlanZero](http://planzero.org/blog/2013/03/07/spidering_the_web_with_casperjs) whose script I started with in the very beginning.  I highly recommend still checking it out for a bare-bones version.\n",
  "readmeFilename": "README.md",
  "_id": "casperjs-spider@0.6.1",
  "_shasum": "1f1a5b50c471729064b8031e94307e2ce3ec7be8",
  "_resolved": "git://github.com/iliakan/casperjs-spider#cf3bca443d074b35608a764c3e4c6ff5e477bd31",
  "_from": "casperjs-spider@git://github.com/iliakan/casperjs-spider"
}
